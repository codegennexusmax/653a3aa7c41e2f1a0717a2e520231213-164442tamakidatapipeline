{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b8edfeb3",
   "metadata": {},
   "source": [
    "***GENERATED CODE FOR tamakidatapipeline PIPELINE.***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4606312b",
   "metadata": {},
   "source": [
    "***DON'T EDIT THIS CODE.***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcb7a599",
   "metadata": {},
   "source": [
    "***CONNECTOR FUNCTIONS TO READ DATA.***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdf03425",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import datetime\n",
    "import logging\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "logging.basicConfig(format='%(levelname)s:%(message)s', level=logging.INFO)\n",
    "\n",
    "\n",
    "class HDFSConnector:\n",
    "\n",
    "    def fetch(spark, config):\n",
    "        ################### INPUT HADOOP HOST PORT TO CONNECT WITH ###############################\n",
    "        hdfs_server = str(os.environ['HDFS_SERVER'])\n",
    "        hdfs_port = int(os.environ['HDFS_PORT'])\n",
    "        df = spark.read.options(header='true', inferschema='true').csv(\n",
    "            f\"hdfs://{hdfs_server}:{hdfs_port}{eval(config)['url']}\", header='true')\n",
    "        display(df.limit(2).toPandas())\n",
    "        return df\n",
    "\n",
    "    def put(df, spark, config):\n",
    "        return df.write.format('csv').options(header='true' if eval(config)[\"is_header\"] == \"Use Header Line\" else 'false',\n",
    "                                              delimiter=eval(config)[\"delimiter\"]).save((\"%s %s\") % (datetime.datetime.now().strftime(\"%Y-%m-%d %H.%M.%S\")+\"_\", eval(config)['url']))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "869cb276",
   "metadata": {},
   "source": [
    "***OPERATION FUNCTIONS***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9d42b91",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "from dask.dataframe import from_pandas\n",
    "import json\n",
    "\n",
    "\n",
    "def replaceValues(df, functionsData, applyOn):\n",
    "    for columnData in applyOn:\n",
    "        for functionData in functionsData:\n",
    "            if functionData['replaceType'] == 'value':\n",
    "                if functionData['replaceValueType'] == 'min':\n",
    "                    minValue = df[columnData['columnName']].min().compute()\n",
    "                    df[columnData['columnName']] = df[columnData['columnName']].replace(\n",
    "                        toReplace, minValue)\n",
    "                elif functionData['replaceValueType'] == 'max':\n",
    "                    maxValue = df[columnData['columnName']].max().compute()\n",
    "                    df[columnData['columnName']] = df[columnData['columnName']].replace(\n",
    "                        toReplace, maxValue)\n",
    "                else:\n",
    "                    df[columnData['columnName']] = df[columnData['columnName']].replace(\n",
    "                        toReplace, functionData['ReplaceWith'])\n",
    "            elif functionData['replaceType'] == 'none':\n",
    "                if functionData['replaceValueType'] == 'min':\n",
    "                    minValue = df[columnData['columnName']].min().compute()\n",
    "                    df[columnData['columnName']\n",
    "                       ] = df[columnData['columnName']].replace(\"\", minValue)\n",
    "                    df[columnData['columnName']\n",
    "                       ] = df[columnData['columnName']].fillna(minValue)\n",
    "                elif functionData['replaceValueType'] == 'max':\n",
    "                    maxValue = df[columnData['columnName']].max().compute()\n",
    "                    df[columnData['columnName']\n",
    "                       ] = df[columnData['columnName']].replace(\"\", maxValue)\n",
    "                    df[columnData['columnName']\n",
    "                       ] = df[columnData['columnName']].fillna(maxValue)\n",
    "                else:\n",
    "                    df[columnData['columnName']] = df[columnData['columnName']].replace(\n",
    "                        \"\", functionData['ReplaceWith'])\n",
    "                    df[columnData['columnName']] = df[columnData['columnName']].fillna(\n",
    "                        functionData['ReplaceWith'])\n",
    "    return df\n",
    "\n",
    "\n",
    "def runDataCleansing(sparkDf, spark, config):\n",
    "    configObj = json.loads(config)\n",
    "    sparkDf.persist(pyspark.StorageLevel.MEMORY_AND_DISK)\n",
    "    df = from_pandas((sparkDf.toPandas()), npartitions=5)\n",
    "    functionList = configObj['functionsApplied']\n",
    "    Data_Cleansing_Methods = {\"replaceBy\": replaceValues,\n",
    "                              \"formula\": calculateFormula,\n",
    "                              \"aggregate\": aggregation,\n",
    "                              \"converttostringtype\": changeToString,\n",
    "                              \"editname\": renameColumns}\n",
    "    for function in functionList:\n",
    "        function['functionName']\n",
    "        df = Data_Cleansing_Methods[function['functionName']](df, function['functionsData'],\n",
    "                                                              function['applyOn'])\n",
    "    sparkDf = spark.createDataFrame(df.compute())\n",
    "\n",
    "    display(sparkDf.limit(2).toPandas())\n",
    "    return sparkDf\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dc0d8cf",
   "metadata": {},
   "source": [
    "***CONNECTOR FUNCTIONS TO WRITE DATA.***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04dfc5e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import requests\n",
    "import datetime\n",
    "import logging\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "logging.basicConfig(format='%(levelname)s:%(message)s', level=logging.INFO)\n",
    "\n",
    "\n",
    "class NumtraConnector:\n",
    "\n",
    "    def put(inStages, inStagesData, stageId, spark, config):\n",
    "        path = eval(config)['server_url']\n",
    "        baseType = eval(config)['baseType']\n",
    "        results_url = eval(config)['results_url']\n",
    "        server = eval(config)['server']\n",
    "        originalfile = eval(config)['orignalKey']\n",
    "        eval(config)['pathOnly']\n",
    "        filename = eval(config)['filename']\n",
    "        eval(config)['ser']\n",
    "        eval(config)['user']\n",
    "        eval(config)['password']\n",
    "        eval(config)['authSource']\n",
    "        eval(config)['user_id']\n",
    "        eval(config)['parent_id']\n",
    "        eval(config)['project_id']\n",
    "        time = str(int(datetime.datetime.now().timestamp()))\n",
    "\n",
    "        inStagesData[inStages[0]]\n",
    "\n",
    "        print(path)\n",
    "        print(baseType)\n",
    "        print(results_url)\n",
    "        print(server)\n",
    "        print(originalfile)\n",
    "        print(filename)\n",
    "\n",
    "        args = {\n",
    "            'url': path,\n",
    "            'baseType': baseType,\n",
    "            'originalfile': originalfile,\n",
    "            'filename': time + filename\n",
    "        }\n",
    "\n",
    "        response = requests.post(results_url, args)\n",
    "        return response\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01c83439",
   "metadata": {},
   "source": [
    "***READING DATAFRAME***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b018bf9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "############## CREATE SPARK SESSION ############################ ENTER YOUR SPARK MASTER IP AND PORT TO CONNECT TO SERVER ################\n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.master('local[1]').getOrCreate()\n",
    "#%run tamakidatapipelineHooks.ipynb\n",
    "try:\n",
    "\t#sourcePreExecutionHook()\n",
    "\n",
    "\ttamakidrivetrain = HDFSConnector.fetch(spark, \"{'url': '/FileStore/platform/testdata/1696425169374_TamakiDrive_Train.csv', 'filename': 'TamakiDrive_Train.csv', 'delimiter': ',', 'file_type': 'Delimeted', 'dbfs_token': '', 'dbfs_domain': '', 'FilePath': '/Finance/Tamaki/TamakiDrive_Train.csv', 'viewFileName': 'TamakiDrive_Train.csv', 'is_header': 'Use Header Line', 'baseType': 'hdfs', 'server_url': '/numtraPlatform/NumtraPlatformV3/uploads/platform/', 'results_url': 'http://ml.numtra.com:44040/api/read/hdfs'}\")\n",
    "\n",
    "except Exception as ex: \n",
    "\tlogging.error(ex)\n",
    "#spark.stop()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8bea0b2",
   "metadata": {},
   "source": [
    "***PERFORMING OPERATIONS***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "748000ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%run tamakidatapipelineHooks.ipynb\n",
    "try:\n",
    "\t#operationPreExecutionHook()\n",
    "\n",
    "datapreparation = runDataCleansing(tamakidrivetrain,spark,json.dumps( {\"url\": \"/FileStore/platform/testdata/1696425169374_TamakiDrive_Train.csv\", \"DataPrepFile\": \"/FileStore/platform/testdata/1696425169374_TamakiDrive_Train.csv\", \"data_source\": \"platfiles\", \"startListenerOnly\": 1, \"dateColumnNames\": [], \"FilePath\": \"/FileStore/platform/extra/653a3aa7c41e2f1a0717a3161696425814/0part.csv\", \"requestRatio\": 3, \"totalRows\": 1466, \"BasicStats\": {\"missingValues\": 0, \"numberOfColumns\": 6, \"numberOfRows\": 1453, \"duplicateRowCount\": 0, \"stats\": [{\"column\": \"date\", \"alias\": \"date\", \"generated\": 0, \"type\": \"String\", \"max\": \"2016-12-31T00:00:00.000Z\", \"min\": \"2013-01-01T00:00:00.000Z\", \"mean\": \"\", \"missing\": 0, \"stddev\": \"\", \"outliers\": [], \"validation\": []}, {\"column\": \"cycling_counter\", \"alias\": \"cycling_counter\", \"generated\": 0, \"type\": \"real\", \"max\": 2262, \"min\": 165, \"mean\": 1092.2016517549896, \"missing\": 0, \"stddev\": 337.44, \"outliers\": [2262, 165, 1954, 230, 207, 240, 211, 222, 214], \"validation\": []}, {\"column\": \"temp\", \"alias\": \"temp\", \"generated\": 0, \"type\": \"real\", \"max\": 24.37857143, \"min\": 6.4357142860000005, \"mean\": 16.16854098751136, \"missing\": 0, \"stddev\": 3.73, \"outliers\": [], \"validation\": []}, {\"column\": \"rain\", \"alias\": \"rain\", \"generated\": 0, \"type\": \"real\", \"max\": 4.15, \"min\": 0, \"mean\": 0.12317864514590503, \"missing\": 0, \"stddev\": 0.37, \"outliers\": [0.228571429, 0.585714286, 0.185714286, 0.95, 1.585714286, 0.121428571, 0.7857142859999999, 0.114285714, 1.242857143, 0.128571429, 0.2071428569999999, 0.942857143, 0.121428571, 4.15, 0.3785714289999999, 2.035714286, 2.121428571, 0.335714286, 0.514285714, 1.392857143, 0.385714286, 0.4, 0.121428571, 0.542857143, 0.235714286, 0.142857143, 0.471428571, 0.142857143, 0.814285714, 1.271428571, 1.821428571, 0.8428571429999999, 2.671428571, 0.1785714289999999, 0.75, 0.307142857, 0.171428571, 0.214285714, 0.185714286, 0.3, 0.157142857, 0.171428571, 0.807142857, 0.15, 0.457142857, 0.6571428570000001, 0.971428571, 0.371428571, 0.614285714, 0.5214285710000001, 0.85, 0.407142857, 1.478571429, 0.264285714, 1.5642857140000002, 0.142857143, 0.121428571, 0.278571429, 0.242857143, 0.314285714, 1.528571429, 0.3285714289999999, 0.164285714, 1.292857143, 2.878571429, 0.285714286, 0.342857143, 0.192857143, 0.135714286, 0.15, 0.3928571429999999, 1.721428571, 0.1785714289999999, 1.1857142859999998, 0.221428571, 1.764285714, 0.992857143, 0.164285714, 0.1785714289999999, 0.357142857, 0.4428571429999999, 2.492857143, 0.485714286, 0.528571429, 0.5642857139999999, 0.792857143, 0.364285714, 0.471428571, 0.142857143, 0.157142857, 1.278571429, 0.3, 0.135714286, 0.142857143, 0.814285714, 0.128571429, 0.121428571, 0.685714286, 0.257142857, 0.342857143, 2.042857143, 1.092857143, 0.4142857139999999, 0.285714286, 0.171428571, 0.5071428570000001, 0.228571429, 0.5, 0.35, 0.214285714, 0.185714286, 0.685714286, 0.492857143, 0.642857143, 0.2, 0.142857143, 0.428571429, 0.371428571, 0.371428571, 1.471428571, 1.2, 0.228571429, 0.192857143, 0.192857143, 0.5642857139999999, 0.3785714289999999, 0.15, 0.185714286, 0.5, 0.792857143, 0.421428571, 0.4428571429999999, 0.5071428570000001, 0.135714286, 0.321428571, 0.7142857140000001, 0.264285714, 0.407142857, 0.114285714, 1.935714286, 0.385714286, 0.164285714, 0.585714286, 0.7214285709999999, 0.292857143, 3.164285714, 0.364285714, 0.1785714289999999, 0.271428571, 0.228571429, 0.164285714, 1.4, 0.3285714289999999, 0.2, 0.5642857139999999, 0.114285714, 1.771428571, 1.5071428569999998, 2.278571429, 1.657142857, 0.2, 0.4142857139999999, 0.1785714289999999, 0.385714286, 0.35, 0.271428571, 0.971428571, 0.285714286, 0.128571429, 0.542857143, 0.728571429, 0.135714286, 0.7857142859999999, 0.4, 0.235714286, 0.7571428570000001, 1.55, 2.5928571430000003, 0.185714286, 0.142857143, 0.307142857, 0.435714286, 1.735714286, 0.135714286, 0.157142857, 0.271428571, 0.992857143, 0.428571429, 0.671428571, 1.128571429, 0.135714286, 0.485714286, 0.35, 0.3, 0.164285714, 0.4642857139999999, 1.014285714, 0.5928571429999999, 2.542857143, 0.4, 0.385714286, 1.4571428569999998, 0.114285714, 0.335714286, 0.192857143, 0.735714286, 0.771428571, 0.978571429, 1.514285714, 0.128571429, 0.307142857, 0.228571429, 0.807142857, 0.121428571, 0.25, 0.7142857140000001, 0.621428571, 0.15, 0.7857142859999999, 0.2, 0.2071428569999999, 0.121428571, 1.307142857, 0.914285714, 0.257142857, 0.228571429, 0.692857143, 0.614285714, 0.814285714, 0.271428571, 1.035714286, 3.6, 0.171428571, 0.15, 0.285714286, 0.5, 0.185714286, 0.7857142859999999, 0.114285714, 0.671428571, 0.3285714289999999, 0.128571429, 0.514285714, 0.535714286, 0.221428571, 0.271428571, 0.6571428570000001, 2.471428571, 0.114285714, 0.164285714, 0.542857143, 0.164285714, 0.4642857139999999, 0.614285714, 0.257142857, 0.921428571, 1.785714286, 2.7714285710000004, 0.135714286, 0.228571429, 0.235714286, 0.114285714, 0.1785714289999999, 0.25, 0.171428571, 0.228571429, 0.342857143, 0.3, 0.828571429, 0.1785714289999999, 0.614285714, 0.214285714, 0.242857143, 0.514285714], \"validation\": []}, {\"column\": \"sun\", \"alias\": \"sun\", \"generated\": 0, \"type\": \"real\", \"max\": 0.978571429, \"min\": 0, \"mean\": 0.4189350377756366, \"missing\": 0, \"stddev\": 0.27, \"outliers\": [], \"validation\": []}, {\"column\": \"wind\", \"alias\": \"wind\", \"generated\": 0, \"type\": \"real\", \"max\": 14.04285714, \"min\": 0.964285714, \"mean\": 5.038573376035788, \"missing\": 0, \"stddev\": 2.45, \"outliers\": [11.26428571, 10.98571429, 11.34285714, 10.73571429, 12.6, 11, 10.84285714, 12.07142857, 12.71428571, 11.03571429, 11.98571429, 11.42142857, 10.66428571, 12.05, 14.04285714, 11.78571429, 13.83571429, 11.65, 13.49285714, 10.63571429, 10.96428571, 11.64285714, 13.15714286, 12.22857143, 11.73571429, 13.97857143, 13.16428571, 10.67142857, 11.40714286, 11.6, 11.73571429, 10.72857143, 10.95, 11.93571429, 12.42857143, 11.07857143, 13.01428571, 13.72142857, 11.02857143, 11.36428571, 12.60714286, 12.19285714, 11.17857143], \"validation\": []}]}, \"predictionPowerScore\": [{\"cycling_counter\": 1, \"date\": 0, \"rain\": 0.2350491399, \"sun\": 0.1475150311, \"temp\": 0, \"wind\": 0}, {\"cycling_counter\": 0, \"date\": 1, \"rain\": 0, \"sun\": 0, \"temp\": 0, \"wind\": 0}, {\"cycling_counter\": 0, \"date\": 0, \"rain\": 1, \"sun\": 0, \"temp\": 0, \"wind\": 0}, {\"cycling_counter\": 0, \"date\": 0, \"rain\": 0.1492094956, \"sun\": 1, \"temp\": 0, \"wind\": 0}, {\"cycling_counter\": 0, \"date\": 0, \"rain\": 0, \"sun\": 0.0122877443, \"temp\": 1, \"wind\": 0}, {\"cycling_counter\": 0, \"date\": 0, \"rain\": 0, \"sun\": 0, \"temp\": 0, \"wind\": 1}], \"HasBasicStats\": 1, \"functionsApplied\": [{\"functionName\": \"replaceBy\", \"applyOn\": [{\"columnName\": \"date\", \"type\": \"String\", \"min\": \"-\", \"max\": \"-\", \"mean\": \"-\"}], \"functionsData\": [{\"replaceType\": \"dedup\", \"asNewColumn\": 0, \"newColumnName\": \"\"}, {\"replaceType\": \"dropna\", \"asNewColumn\": 0, \"newColumnName\": \"\"}]}, {\"functionName\": \"replaceBy\", \"applyOn\": [{\"columnName\": \"cycling_counter\", \"type\": \"real\", \"min\": \"165.0\", \"max\": \"2262.0\", \"mean\": \"337.1\"}], \"functionsData\": [{\"replaceType\": \"dropna\", \"asNewColumn\": 0, \"newColumnName\": \"\"}]}, {\"functionName\": \"replaceBy\", \"applyOn\": [{\"columnName\": \"temp\", \"type\": \"real\", \"min\": \"6.4\", \"max\": \"24.4\", \"mean\": \"3.7\"}, {\"columnName\": \"rain\", \"type\": \"real\", \"min\": \"0.0\", \"max\": \"4.2\", \"mean\": \"0.4\"}, {\"columnName\": \"sun\", \"type\": \"real\", \"min\": \"0.0\", \"max\": \"1.0\", \"mean\": \"0.3\"}, {\"columnName\": \"wind\", \"type\": \"real\", \"min\": \"1.0\", \"max\": \"14.0\", \"mean\": \"2.5\"}], \"functionsData\": [{\"replaceType\": \"dropna\", \"asNewColumn\": 0, \"newColumnName\": \"\"}]}], \"functionChanges\": [{\"columnName\": \"date\", \"functionName\": \"Replace Outliers\", \"Type\": \"String\", \"Parameters\": [{\"replaceType\": \"dedup\", \"asNewColumn\": 0, \"newColumnName\": \"\"}, {\"replaceType\": \"dropna\", \"asNewColumn\": 0, \"newColumnName\": \"\"}]}, {\"columnName\": \"cycling_counter\", \"functionName\": \"Replace Outliers\", \"Type\": \"real\", \"Parameters\": [{\"replaceType\": \"dropna\", \"asNewColumn\": 0, \"newColumnName\": \"\"}]}, {\"columnName\": \"temp\", \"functionName\": \"Replace Outliers\", \"Type\": \"real\", \"Parameters\": [{\"replaceType\": \"dropna\", \"asNewColumn\": 0, \"newColumnName\": \"\"}]}, {\"columnName\": \"rain\", \"functionName\": \"Replace Outliers\", \"Type\": \"real\", \"Parameters\": [{\"replaceType\": \"dropna\", \"asNewColumn\": 0, \"newColumnName\": \"\"}]}, {\"columnName\": \"sun\", \"functionName\": \"Replace Outliers\", \"Type\": \"real\", \"Parameters\": [{\"replaceType\": \"dropna\", \"asNewColumn\": 0, \"newColumnName\": \"\"}]}, {\"columnName\": \"wind\", \"functionName\": \"Replace Outliers\", \"Type\": \"real\", \"Parameters\": [{\"replaceType\": \"dropna\", \"asNewColumn\": 0, \"newColumnName\": \"\"}]}], \"fileheader\": [{\"field\": \"date\", \"alias\": \"date\", \"generated\": 0, \"position\": 1, \"type\": \"String\"}, {\"field\": \"cycling_counter\", \"alias\": \"cycling_counter\", \"generated\": 0, \"position\": 2, \"type\": \"real\"}, {\"field\": \"temp\", \"alias\": \"temp\", \"generated\": 0, \"position\": 3, \"type\": \"real\"}, {\"field\": \"rain\", \"alias\": \"rain\", \"generated\": 0, \"position\": 4, \"type\": \"real\"}, {\"field\": \"sun\", \"alias\": \"sun\", \"generated\": 0, \"position\": 5, \"type\": \"real\"}, {\"field\": \"wind\", \"alias\": \"wind\", \"generated\": 0, \"position\": 6, \"type\": \"real\"}]}))\n",
    "\t#operationPostExecutionHook(datapreparation)\n",
    "\n",
    "except Exception as ex: \n",
    "\tlogging.error(ex)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c243effe",
   "metadata": {},
   "source": [
    "***WRITING DATAFRAME***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "504b28e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%run tamakidatapipelineHooks.ipynb\n",
    "try:\n",
    "\t#sinkPreExecutionHook()\n",
    "\n",
    "\ttamaki = NumtraConnector.fetch(spark, \"{'samplefile': '/FileStore/platform/sampleData/653a3aa7c41e2f1a0717a315/part-00000-495e3028-ba48-44ce-8bd0-d1fd67fcc4a2-c000.csv', 'samplecount': 144, 'originalcount': 1466, 'orignalKey': '/FileStore/platform/testdata/1696425169374_TamakiDrive_Train.csv', 'pathOnly': '/Finance/Tamaki', 'project_id': '6512e4bdb91dbaa301dd0efe', 'parent_id': '6512e4bdb91dbaa301dd0efe', 'original_schema': [{'checked': True, 'inherited': True, 'is_categorical': False, 'bad_values': '', 'nullable': 'true', 'field': 'date', 'alias': 'date', 'type': 'numeric', 'position': '0'}, {'checked': True, 'inherited': True, 'is_categorical': False, 'bad_values': '', 'nullable': 'true', 'field': 'cycling_counter', 'alias': 'cycling_counter', 'type': 'numeric', 'position': '1'}, {'checked': True, 'inherited': True, 'is_categorical': False, 'bad_values': '', 'nullable': 'true', 'field': 'temp', 'alias': 'temp', 'type': 'real', 'position': '2'}, {'checked': True, 'inherited': True, 'is_categorical': False, 'bad_values': '', 'nullable': 'true', 'field': 'rain', 'alias': 'rain', 'type': 'real', 'position': '3'}, {'checked': True, 'inherited': True, 'is_categorical': False, 'bad_values': '', 'nullable': 'true', 'field': 'sun', 'alias': 'sun', 'type': 'real', 'position': '4'}, {'checked': True, 'inherited': True, 'is_categorical': False, 'bad_values': '', 'nullable': 'true', 'field': 'wind', 'alias': 'wind', 'type': 'real', 'position': '5'}], 'actual_schema': [{'checked': True, 'inherited': True, 'is_categorical': False, 'bad_values': '', 'nullable': 'true', 'field': 'date', 'alias': 'date', 'type': 'numeric', 'position': '0'}, {'checked': True, 'inherited': True, 'is_categorical': False, 'bad_values': '', 'nullable': 'true', 'field': 'cycling_counter', 'alias': 'cycling_counter', 'type': 'numeric', 'position': '1'}, {'checked': True, 'inherited': True, 'is_categorical': False, 'bad_values': '', 'nullable': 'true', 'field': 'temp', 'alias': 'temp', 'type': 'real', 'position': '2'}, {'checked': True, 'inherited': True, 'is_categorical': False, 'bad_values': '', 'nullable': 'true', 'field': 'rain', 'alias': 'rain', 'type': 'real', 'position': '3'}, {'checked': True, 'inherited': True, 'is_categorical': False, 'bad_values': '', 'nullable': 'true', 'field': 'sun', 'alias': 'sun', 'type': 'real', 'position': '4'}, {'checked': True, 'inherited': True, 'is_categorical': False, 'bad_values': '', 'nullable': 'true', 'field': 'wind', 'alias': 'wind', 'type': 'real', 'position': '5'}], 'server': 'https://ml.numtra.com:443', 'server_url': '/numtraPlatform/NumtraPlatformV3/uploads/platform/', 'delimiter': ',', 'file_type': 'Delimeted', 'filename': 'TamakiTrainDP.csv', 'token': '', 'domain': '', 'is_header': 'Use Header Line', 'url': '/FileStore/platform/uploadedSourceFiles/part-00000-dd86b823-bdcb-4944-b7a8-4488f1b25540-c000.csv', 'results_url': 'http://ml.numtra.com:44040/api/read/hdfs'}\")\n",
    "\n",
    "except Exception as ex: \n",
    "\tlogging.error(ex)\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
